{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUDW38wIy_z5"
      },
      "source": [
        "# COGS 118A- Project Proposal : Walmart Trip Type Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX_kySZiy_z8"
      },
      "source": [
        "### Peer Review\n",
        "\n",
        "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
        "\n",
        "Both the project proposal and project checkpoint will have peer review."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQH4PobQy_z9"
      },
      "source": [
        "# Names\n",
        "- Daniel Milton \n",
        "- Isabella Gonzalez\n",
        "- Dhruva Kolikineni\n",
        "- Harini Adivikolanu\n",
        "- Brandon Rocchio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ8VCd3Ky_z-"
      },
      "source": [
        "# Abstract \n",
        "\n",
        "  Classification involves predicting discrete class labels for unlabeled data. given information on the data. The data we are working with is information from individuals' shopping trips at Walmart. The data is broken down into 7 observations, one of which is the trip type which tells us what type of shopping trip this customer was on, visit number which organizes the data into individual shopping trips, weekday that the trip was done on, UPC number of the item purchased, department of purchase and the fineline number which is a number that Walmart made helping us specify the items purchased. Given certain data such as what weekday it is, what department it was in, and what the UPC was, our goal is to be able to predict what type of shopping trip someone was on based off of a couple pieces of data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa6UC7ANy_z-"
      },
      "source": [
        "# Background\n",
        "\n",
        "Although supervised classification methods have been studied greatly throughout the years, research specific to this problem, on classifying a grocery trip based on the items bought remains low. There are multiple classification algorithms we can attempt in order to classify the 38 different types of shopping trips there are. K nearest neighbors, decision trees, random forest classifiers, neural networks and logistic regression are commonly used in order to solve classification problems. Due to the low amount of research done in this specific problem area, this background section will be a small literature review of potential classification algorithms to use for our problem. \n",
        "\n",
        "Firstly, K Nearest Neighbors works based on the idea that for a target variable, the k number of patterns nearest to that target variable can provide useful information in order to properly classify the target variable. KNN assigns the target variable the classification of the majority of the nearest neighbors </a>[<sup>[1]</sup>](#kramernote). The downfalls of KNN are that there is no right 'K' to choose and it can be computationally inefficient. Second, Decision Trees are another classification method we want to attempt, these are popular due to their good accuracy scores and their computational efficiency </a>[<sup>[2]</sup>](#srivastavanote). The random forest classifier works by using multiple tree classifiers where each classifier is generated by using a random vector and each tree vottes for the most 'popular' class to classify an input vector </a>[<sup>[3]</sup>](#palnote). This paper uses random forests to classify remote sensing which they concluded was just as accurate as using a support vector machine.\n",
        "\n",
        "Neural Networks and logistic regression are other potential algorithms we would like to try to classif our data with, there was no literature on any similar classification task to our project but a paper revealed that these two algorithms share common roots in statistical pattern recognition and that neural networks can be seen as a type of generalization from logistic regression </a>[<sup>[4]</sup>](#dreiseitlnote). Lastly, upon multiple attempts to find related work, Cui et al attempted this trip type classification using deep embedding logistic regression which incorporates logistic regression into a deep and narrow neural network </a>[<sup>[5]</sup>](#cuinote). We are hoping as we implement some of these algorithms to produce results and a discussion that can help future research for stores like Walmart to improve customers' shopping experiences or help understand/solve problems similar to this. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRRQ5J88y_z_"
      },
      "source": [
        "# Problem Statement\n",
        "\n",
        "\n",
        "\n",
        "Walmart currently employs a proprietary method to catogorize shopping trips into 38 distinct types. We have set out to create a clustering/catagorization model that, given a limited set of customer behavior features, predicts the shopping trip types. \n",
        "\n",
        "As an example for what these trip types may be: a customer may make a small daily dinner trip, a weekly large grocery trip, a trip to buy gifts for an upcoming holiday, or a seasonal trip to buy clothes.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnoegOO5y_z_"
      },
      "source": [
        "# Data\n",
        "\n",
        "\n",
        "Dataset #1: Train dataset provided by Walmart that categorizes 421,000 trips into 38 distinct types\n",
        "\n",
        "- Link: https://github.com/hadiviko/Walmart_Kaggle_Competition/blob/master/train.csv\n",
        "- 421,000 observations and 7 variables \n",
        "- An observation consists of these critical variables:\n",
        "  - TripType: a categorical id (numeric value between 1-38) that represents that classifies the type of shopping trip a customer made\n",
        "  - VisitNumber: a unique numeric id (~90,000) that corresponds to a single trip made by a single customer\n",
        "  - Weekday: the weekday the trip was made\n",
        "  - Upc: the universal product code of the product purchased\n",
        "  - ScanCount: the number of the particular products purchased (-1 represents a product return)\n",
        "  - DepartmentDescription: a description of the department (72 categories) corresponding with the item purchased\n",
        "  - FinelineNumber: a numerical category for each product, created by Walmart\n",
        "- Possible transformations: converting categorical values into numerical values, grouping data to understand the unique features of a particular trip type, etc.\n",
        "\n",
        "Dataset #2: Test dataset consisting of the same variables as above\n",
        "- Link: https://github.com/hadiviko/Walmart_Kaggle_Competition/blob/master/test%202%20(1).csv "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFUeTb5ty_0A"
      },
      "source": [
        "# Proposed Solution\n",
        "\n",
        "Our proposed solution is to use train and fit a model to the traiing data and evaluate its perfromance on the testing data, all the whiel using cross validation to verify the accuracy of our results.\n",
        "\n",
        "The model we intend on using is still up for our team to decide, but given the nature of the problem of non-binary classification into 38 distinct catagories, we have isolated some models we  beileve might be best suited for the task:\n",
        "\n",
        "* K- Nearest Neighbors\n",
        "* Decistion tree classifiers\n",
        "* Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg3K7bMky_0B"
      },
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "Our evaluation metric will involve using a multi-class logarithmic loss fuction. For each row, we will find a set of predicted probabilities for every trip type and apply the logarithmic loss formula. As we optimize our model, we hope to minimize this function as a metric of how well our model is performing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1LMoSXly_0B"
      },
      "source": [
        "# Ethics & Privacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsRpt3why_0C"
      },
      "source": [
        "Our data does not involve anyones data or identity so it would be difficult to find a breach of ethics or privacy. One ethical dilemma that might arise is the increasing amount of data available to big corporations and how theyâ€™re using this big data to fine tune their products to keep the average person consuming even more. It would be good to question whether it is completely ethical for corporations to treat everyone as a number to maximize their profits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOUVQuj6y_0C"
      },
      "source": [
        "# Team Expectations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKxaVqoNy_0C"
      },
      "source": [
        "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
        "* *Arrange bi-weekly meetings that works with everyones schedule*\n",
        "* *Use a discord server to communicate with one another*\n",
        "* *Make use of project managment software to track progress*\n",
        "* *Be mindful of git -pull-push-overwrites such that no code is overwritten or needlessly repeated*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNnwFiCTy_0D"
      },
      "source": [
        "# Project Timeline Proposal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X08OY71Ty_0D"
      },
      "source": [
        "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
        "\n",
        "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
        "|---|---|---|---|\n",
        "| 4/24  | 3:30 pm  | Edit, finalize, and submit proposal; Search for datasets| Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
        "| 4/26  | 7 PM  | Import & Wrangle Data ,do some EDA | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
        "| 4/28  | 7 PM  | Finalize wrangling/EDA; Begin programming for project | Discuss/edit project code|\n",
        "| 5/09  | 7 PM  | Continue working on project| Get Checkpoint done |\n",
        "| 5/17  | 7 pm  | Continue Working on Project| Debug | Analyze Results |\n",
        "| 5/23  | 7 pm  | Finalize Project, Conclusions, and Discussions | Discuss Conclusions and or any problems encountered |\n",
        "| 6/08 | Before 11:59 PM  | NA | Turn in Final Project  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbuBgdVNy_0E"
      },
      "source": [
        "# Footnotes\n",
        "<a name=\"kramernote\"></a>1.[^](#kramer): Oliver Kramer. K Nearest Neighbors. https://link.springer.com/chapter/10.1007/978-3-642-38652-7_2. <br> \n",
        "\n",
        "<a name=\"srivastavanote\"></a>2.[^](#srivastava): Srivastava et al. (1999) Parallel Forumlations of Decision Tree Classfication Algorithms. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.7475&rep=rep1&type=pdf <br>\n",
        "\n",
        "<a name=\"palnote\"></a>3.[^](#pal): M. Pal (2005).Random forest classifier for remote sensing classification. https://www.tandfonline.com/doi/pdf/10.1080/01431160412331269698?casa_token=e78vG4sBDLcAAAAA:p9nt0mSjEMuazyQsDjprmwIIFt9aNRk9EtF7eKRyNozF6FsAskuvXKrMxnnftOK0xFjlUm5MX9g. \n",
        "\n",
        "<a name=\"dreiseitlnote\"></a>4.[^](#dreiseitl): Stephan Dreiseitl and Lucila Ohno_Machado. (2002). Logistic regression and artificial neural network classification models: a methodology review. https://www.sciencedirect.com/science/article/pii/S1532046403000340. \n",
        "\n",
        "<a name=\"cuinote\"></a>5.[^](#cui): Cui et al. (2018). Deep Embedding Logistic Regression. https://ieeexplore.ieee.org/document/8588790 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j20tPYOey_0F"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Copy of ProposalGroup004-Sp22.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}